<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Anurag Gade</title>

    <meta name="author" content="Anurag Gade">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/web_development_coding_code_browse_browser_icon-icons.com_59980.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Anurag Gade
                </p>
                <p style="text-align: center; color:red"><strong>**Searching for full-time Computer Vision roles**</strong></p>
                <p>I am a senior year undergraduate at <a href="https://www.bits-pilani.ac.in/hyderabad/">BITS Pilani Hyderabad Campus</a> majoring in Electrical and Electronics Engineering with a minor in Computing and Intelligence.  
                </p>
                <p>
                  My work spans the engrossing fields of Computer Vision, Image Processing and Representative Learning. I am also interested in ROS Programming, and Internet of Things (IoT). 
                </p>
                <p>
                  I am currently pursuing my undergraduate thesis at the <a href="https://https://pnl.bwh.harvard.edu/">Psychiatry Neuroimaging Laboratory</a> at <a href="https://hms.harvard.edu/">Harvard Medical School</a> under the supervision of <a href="https://dms.hms.harvard.edu/people/yogesh-rathi">Prof. Yogesh Rathi</a> on Neural Fields for MRI super-resolution. I am also remotely working as a research intern at the <a href="https://www.tum.de/en/">Technical University of Munich</a> under the supervision of <a href="https://ai-med.de/people/christian-wachinger/">Prof. Christian Wachinger</a> and <a href="https://mogvision.github.io/">Dr. Morteza Ghahremani</a> on Contrastive Learning. 
                </p>
                <p>
                  I have previously interned at the <a href="https://sensein.group/">Senseable Intelligence Group, MIT</a> under the supervision of <a href="https://satra.cogitatum.org/">Prof. Satrajit Ghosh</a> on random-oriented MRI slice segmentation. I have also interned remotely at the <a href="acps.uia.no">Autonomous and Cyber-Physical Systems Group</a>, University of Agder (UiA) under the supervision of <a href="https://www.uia.no/en/kk/profil/lingac">Prof. Linga Reddy C</a> on UAV classification using RF fingerprints.
                </p>
                <p>
                  I am extremely fortunate to collaborate and work under the supervision of <a href="https://www.bits-pilani.ac.in/hyderabad/rajesh-kumar-tripathy/">Prof. Rajesh Kumar Tripathy</a> and <a href="https://universe.bits-pilani.ac.in/hyderabad/parikshitsahatiya/Profile">Prof. Parikshit Sahatiya</a> at BITS Pilani. 
                </p>
                <p style="text-align:center">
                  <a href="mailto:anuraggade16@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/AnuragGade_UpdatedResume.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=YBBVKYAAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/anurag-gade-948071205/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Anurag-Gade/">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/AnuragGitHubPic-modified.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/AnuragGitHubPic-modified.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  <strong>Asterisk (*) indicates equal contribtion (co-first author)</strong>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/2DEWT_Decompositions.png" width="300" alt="Boundary_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/document/10258390/authors#authors">
                  <span class="papertitle">Multiscale Analysis Domain Interpretable Deep Neural Network for Detection of Breast Cancer Using Thermogram Images
                  </span>
                </a>
                <br>
                <strong>Anurag Gade</strong>,
                Dinesh Kumar Dash, T. Mita Kumari, Samit Kumar Ghosh, Rajesh Kumar Tripathy, Ram Bilas Pachori
                <br>
                <em>IEEE Transactions on Instrumentation and Measurement</em>, 2023
                <br>
                <a href="https://ieeexplore.ieee.org/document/10258390/authors#authors">Paper</a> / <a href="data/gade2023multiscale.bib">bibtex</a>
                <p>Detecting breast cancer from thermograms using 2D Empirical Wavelet Transform (2D EWT) with fixed boundary points for multiscale analysis of the input scans, which provides interpretability in terms of frequency ranges. The obtained modes are inputs to the Deep Feature Extractor Blocks (DFEBs), which is the core to the proposed Multiscale Analysis Domain Interpretable Deep Learning (MSADIDL) architecture with which an accuracy of <strong>99.54%</strong> was obtained.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/SVD_LNSP.png" width="300" alt="Boundary_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/10036027">
                  <span class="papertitle">Detection of Myocardial Infarction From 12-Lead ECG Trace Images Using Eigendomain Deep Representation Learning
                  </span>
                </a>
                <br>
                Sathvik Bhaskarpandit<strong>*</strong>, <strong>Anurag Gade*</strong>, Shaswati Dash, Dinesh Kumar Dash, Rajesh Kumar Tripathy, Ram Bilas Pachori
                <br>
                <em>IEEE Transactions on Instrumentation and Measurement</em>, 2023
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/10036027">Paper</a> / <a href="data/bhaskarpandit2023detection.bib">bibtex</a>
                <p>Myocardial Infarction detection from ECG trace images using singular value decomposition (SVD) which extracts the local information based on eigentriple grouping of the input images. A Deep Representation Learning (DRL) architecture is proposed which uses pre-trained EfficientNetV2B2 models parallely for feature extraction from the obtained modes. A classification accuracy of <strong>99.03%</strong> was obtained using the proposed eigendomain DRL architecture.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/PatternDetectionAlphabet.png" width="300" alt="Boundary_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/10262363">
                  <span class="papertitle">Development of Flexible ReS2/MXene Based Electromechanical Sensor for Deep Learning Assisted Temporal Dependent Alphabet Pattern Recognition
                  </span>
                </a>
                <br>
                Sohel Siraj, Naveen Bokka, <strong>Anurag Gade</strong>, Sarang Akella, Chandra Sekhar Reddy Kolli, Parikshit Sahatiya
                <br>
                <em>IEEE Journal on Flexible Electronics (J-FLEX)</em>, 2023
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/10262363">Paper</a> / <a href="data/siraj2023development.bib">bibtex</a>
                <p>Using a fabricated ReS<sub>2</sub>/MXene sensor for recording the pressure-time characteristics of the written alphabet. The recorded data is transformed into an image representation after which the proposed lightweight Convolutional Neural Network (CNN) architecture was used to classify the input images. The CNN model was loaded on the RaspberryPi board and an Android application was used to demonstrate a use case of the setup acting as a forgery detection system. An accuracy of <strong>96.20%</strong> was obtained using the lightweight CNN architecture proposed in this paper.</p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/WSSTPipeline.png" width="300" alt="Boundary_png" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/10027150">
                  <span class="papertitle">Classification of UAVs using Time-Frequency Analysis of Remote Control Signals and CNN
                  </span>
                </a>
                <br>
                Rakesh Reddy Yakkati, <strong>Anurag Gade</strong>, Balu Harshavardan Koduru, Bethi Pardhasaradhi, Linga Reddy Cenkeramaddi
                <br>
                <em>IEEE International Symposium on Smart Electronic Systems (iSES)</em>, 2022
                <br>
                <a href="https://ieeexplore.ieee.org/abstract/document/10027150">Paper</a> / <a href="data/yakkati2022classification.bib">bibtex</a>
                <p>For classifying the unmanned aerial vehicle (UAV) using radio-frequency (RF) fingerprints, Wavelet Synchrosqueezed Transform (WSST) is used to transform the fingerprints to time-frequency images which is the input to the proposed lightweight Convolutional Neural Network (CNN) model. The proposed model is of 387 kilobytes (kB), having a classification accuracy of <strong>99.09%</strong> and an inference time of <strong>25.54 ms</strong> on the Raspberry Pi.</p>
              </td>
            </tr>


            

          </tbody></table>

          <!--
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            

            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
            -->
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Website Template taken from <a href="https://jonbarron.info/">Jon barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
